{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T13:21:44.431059Z",
     "start_time": "2025-11-22T13:13:38.498117Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import threading\n",
    "import queue\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "from collections import defaultdict\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# RECOMMENDATION: Use .engine (TensorRT) or .onnx files for 2x-5x speedup\n",
    "MODEL_PATH = 'data/model/best_detect.pt'  # Change to 'best5.engine' after exporting\n",
    "MODEL_CLASSIFY_PATH = 'data/model/best_classify.pt'  # Change to 'best_classify.engine' after exporting\n",
    "VIDEO_PATH = \"D:\\\\Recordings\\\\2025_11_07\\\\20251107030005_20251107040005_3.mp4\"\n",
    "TRACKER_CONFIG = 'custom_bytetrack.yaml'\n",
    "\n",
    "N_FRAMES_OPEN_CONFIRM = 3\n",
    "M_FRAMES_CLOSED_CONFIRM = 4\n",
    "\n",
    "# Reduced visualization resolution (width) for faster display\n",
    "DISPLAY_WIDTH = 1280\n",
    "# --- END OF CONFIGURATION ---\n",
    "\n",
    "# --- Shared Resources for Threading ---\n",
    "classification_queue = queue.Queue()\n",
    "class_counts = defaultdict(int)\n",
    "counts_lock = threading.Lock() # Prevents race conditions when reading/writing counts\n",
    "\n",
    "def classifier_worker():\n",
    "    \"\"\"\n",
    "    Worker thread that waits for ROIs (images of bags) and classifies them.\n",
    "    This runs in the background so the video doesn't stutter.\n",
    "    \"\"\"\n",
    "    print(\"Loading classification model in worker thread...\")\n",
    "    # Load model inside the thread or pass it in.\n",
    "    # NOTE: For TensorRT/Exported models, loading here is safer for thread isolation.\n",
    "    model_classify = YOLO(MODEL_CLASSIFY_PATH)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            # Wait for an item, but allow checking for exit every second\n",
    "            item = classification_queue.get(timeout=1)\n",
    "        except queue.Empty:\n",
    "            continue\n",
    "\n",
    "        if item is None: # Sentinel to kill thread\n",
    "            break\n",
    "\n",
    "        track_id, roi_img = item\n",
    "\n",
    "        # Run inference (verbose=False is slightly faster)\n",
    "        results = model_classify(roi_img, verbose=False)\n",
    "\n",
    "        detected_label = \"Unknown\"\n",
    "        # Logic to extract label\n",
    "        if results[0].probs is not None:\n",
    "            detected_label = results[0].names[results[0].probs.top1]\n",
    "        elif len(results[0].boxes) > 0:\n",
    "            top_cls = int(results[0].boxes.cls[0])\n",
    "            detected_label = model_classify.names[top_cls]\n",
    "\n",
    "        with counts_lock:\n",
    "            class_counts[detected_label] += 1\n",
    "\n",
    "        # print(f\" [Async] Track {track_id} -> {detected_label}\")\n",
    "        classification_queue.task_done()\n",
    "\n",
    "# Start the classification thread\n",
    "t = threading.Thread(target=classifier_worker, daemon=True)\n",
    "t.start()\n",
    "\n",
    "# --- Main Tracker Setup ---\n",
    "model = YOLO(MODEL_PATH)\n",
    "class_names = model.names\n",
    "\n",
    "try:\n",
    "    OPEN_CLASS_NAME = 'bread-bag-opened'\n",
    "    CLOSED_CLASS_NAME = 'bread-bag-closed'\n",
    "    names_to_ids = {v: k for k, v in class_names.items()}\n",
    "    open_class_id = names_to_ids[OPEN_CLASS_NAME]\n",
    "    closed_class_id = names_to_ids[CLOSED_CLASS_NAME]\n",
    "except KeyError as e:\n",
    "    print(f\"Error: Class {e} not found.\")\n",
    "    exit()\n",
    "\n",
    "track_states = {}\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "\n",
    "# Optimization: Pre-calculate resize factor for display to avoid resizing full arrays constantly if not needed\n",
    "# Or simply resize the final image.\n",
    "frame_count = 0\n",
    "start_time = time.time()\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    # Optimization: Run tracking.\n",
    "    # 'persist=True' is required for tracking.\n",
    "    # 'verbose=False' suppresses printing to console (saves I/O time)\n",
    "    results = model.track(frame, persist=True, tracker=TRACKER_CONFIG, verbose=False)\n",
    "\n",
    "    # Extract data locally to avoid repeated access\n",
    "    boxes = results[0].boxes\n",
    "    current_detections = {}\n",
    "\n",
    "    # Optimization: Manual Drawing is faster than results[0].plot()\n",
    "    # We will draw on 'frame' directly.\n",
    "    if boxes.id is not None:\n",
    "        # Move tensors to CPU once and convert to numpy/list\n",
    "        track_ids = boxes.id.int().cpu().tolist()\n",
    "        cls_ids = boxes.cls.int().cpu().tolist()\n",
    "        xyxys = boxes.xyxy.cpu().tolist()\n",
    "\n",
    "        for track_id, cls_id, box in zip(track_ids, cls_ids, xyxys):\n",
    "            current_detections[track_id] = cls_id\n",
    "\n",
    "            # Draw Bounding Box (Green for Closed, Red for Open, White for others)\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            color = (200, 200, 200)\n",
    "            if cls_id == open_class_id: color = (0, 0, 255)     # Red\n",
    "            elif cls_id == closed_class_id: color = (0, 255, 0) # Green\n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "\n",
    "            # Draw Label (Simplified)\n",
    "            label = f\"{track_id}: {class_names[cls_id]}\"\n",
    "            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "            # --- State Machine Logic ---\n",
    "            # Retrieve or create state\n",
    "            if track_id not in track_states:\n",
    "                track_states[track_id] = {'state': 'detecting_open', 'open_count': 0, 'closed_count': 0}\n",
    "\n",
    "            state_info = track_states[track_id]\n",
    "\n",
    "            # Logic\n",
    "            if state_info['state'] == 'detecting_open':\n",
    "                if cls_id == open_class_id:\n",
    "                    state_info['open_count'] += 1\n",
    "                else:\n",
    "                    state_info['open_count'] = 0\n",
    "\n",
    "                if state_info['open_count'] >= N_FRAMES_OPEN_CONFIRM:\n",
    "                    state_info['state'] = 'detecting_closed'\n",
    "                    state_info['open_count'] = 0\n",
    "\n",
    "            elif state_info['state'] == 'detecting_closed':\n",
    "                if cls_id == closed_class_id:\n",
    "                    state_info['closed_count'] += 1\n",
    "                else:\n",
    "                    state_info['closed_count'] = 0\n",
    "\n",
    "                if state_info['closed_count'] >= M_FRAMES_CLOSED_CONFIRM:\n",
    "                    state_info['state'] = 'counted'\n",
    "\n",
    "                    # --- ASYNC CLASSIFICATION TRIGGER ---\n",
    "                    # Validate coordinates\n",
    "                    h, w, _ = frame.shape\n",
    "                    cx1, cy1 = max(0, x1), max(0, y1)\n",
    "                    cx2, cy2 = min(w, x2), min(h, y2)\n",
    "\n",
    "                    if cx2 > cx1 and cy2 > cy1:\n",
    "                        # Copy ROI to avoid memory issues when frame changes\n",
    "                        roi = frame[cy1:cy2, cx1:cx2].copy()\n",
    "                        # Push to queue\n",
    "                        classification_queue.put((track_id, roi))\n",
    "\n",
    "    # Clean up old tracks from state dictionary\n",
    "    # (Optional: Keeps dictionary small)\n",
    "    for tid in list(track_states.keys()):\n",
    "        if tid not in current_detections:\n",
    "            # You might want to keep them briefly or delete immediately\n",
    "            # Here we just reset counts if lost\n",
    "            track_states[tid]['open_count'] = 0\n",
    "            track_states[tid]['closed_count'] = 0\n",
    "\n",
    "    # --- Display Stats ---\n",
    "    # Read counts safely\n",
    "    with counts_lock:\n",
    "        display_counts = list(class_counts.items())\n",
    "\n",
    "    y_offset = 60\n",
    "    cv2.putText(frame, \"FPS: calculate if needed\", (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 1.6, (0, 255, 255), 3)\n",
    "\n",
    "    sorted_counts = sorted(display_counts)\n",
    "    for cls_name, count in sorted_counts:\n",
    "        y_offset += 70\n",
    "        text = f\"{cls_name}: {count}\"\n",
    "        cv2.putText(frame, text, (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 3)\n",
    "\n",
    "    # Resize only for display (keeps processing on original resolution)\n",
    "    if DISPLAY_WIDTH:\n",
    "        h, w = frame.shape[:2]\n",
    "        scale = DISPLAY_WIDTH / w\n",
    "        frame_disp = cv2.resize(frame, (int(w*scale), int(h*scale)))\n",
    "    else:\n",
    "        frame_disp = frame\n",
    "\n",
    "    cv2.imshow(\"Optimized Tracker\", frame_disp)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "4ca979936b913618",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading classification model in worker thread...\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T02:52:13.882460Z",
     "start_time": "2025-11-26T02:52:13.655646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO('data/model/best_detect.pt')\n",
    "\n",
    "# 2. Get the class names dictionary\n",
    "class_dict = model.names\n",
    "print(f\"Detected Classes: {class_dict}\")"
   ],
   "id": "4d5096c4bffdd031",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Classes: {0: 'bread-bag-closed', 1: 'bread-bag-opened'}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T15:00:59.719760Z",
     "start_time": "2025-11-26T15:00:59.674445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "fps = 30\n",
    "if fps <= 0 or fps > 120:\n",
    "    fps = 20.0\n",
    "frame_duration = 1.0 / fps\n",
    "start_time = time.time()\n",
    "print(f\"startTime: {start_time}\")\n",
    "time.sleep(0.02)\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"elapsed: {elapsed}\")\n",
    "# Sleep until next frame should be grabbed\n",
    "sleep_time = frame_duration - elapsed\n",
    "print(f\"Frame Duration : {frame_duration}, Elapsed : {elapsed}, Sleep : {sleep_time}\")\n",
    "if sleep_time > 0:\n",
    "    time.sleep(sleep_time)"
   ],
   "id": "9d6df91876bd3940",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startTime: 1764169259.681691\n",
      "elapsed: 0.021376371383666992\n",
      "Frame Duration : 0.03333333333333333, Elapsed : 0.021376371383666992, Sleep : 0.01195696194966634\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T17:16:13.374907Z",
     "start_time": "2025-11-27T17:16:12.043009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Improved hardware/software video decode pipeline for RDK X5.\n",
    "- Hardware decode via hobot_codec if available.\n",
    "- Software fallback via ffmpeg (requires known resolution).\n",
    "\n",
    "Usage:\n",
    "    - Edit SOURCE and RESOLUTION below.\n",
    "    - Run: python3 hw_decode_singlefile_fixed.py\n",
    "\"\"\"\n",
    "\n",
    "import shutil\n",
    "import subprocess\n",
    "import time\n",
    "from typing import Generator, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# ---------------------------\n",
    "# USER CONFIG\n",
    "# ---------------------------\n",
    "DEFAULT_SOURCE = \"test.mp4\"  # or \"rtsp://192.168.1.10/stream\" or \"/path/to/input.h264\"\n",
    "OUTPUT_WINDOW = True           # set False if running headless\n",
    "DEFAULT_WIDTH = 640            # Enter known width for file/software fallback\n",
    "DEFAULT_HEIGHT = 360           # Enter known height for file/software fallback\n",
    "# ---------------------------\n",
    "\n",
    "class Decoder:\n",
    "    \"\"\"\n",
    "    Thin wrapper: hobot_codec for hardware decode, or ffmpeg SW decode with known resolution.\n",
    "    \"\"\"\n",
    "    def __init__(self, codec_type: str = \"h264\", prefer_hw: bool = True, width: Optional[int] = None, height: Optional[int] = None):\n",
    "        self.codec_type = codec_type.lower()\n",
    "        self.hw = False\n",
    "        self.decoder = None\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.software_proc = None\n",
    "\n",
    "        # Try hardware first\n",
    "        if prefer_hw:\n",
    "            try:\n",
    "                from hobot_codec import Codec, CodecType  # type: ignore\n",
    "                ctype = CodecType.H264 if \"264\" in self.codec_type else CodecType.H265\n",
    "                self.decoder = Codec(\n",
    "                    codec_type=ctype,\n",
    "                    is_decoder=True,\n",
    "                    input_mode=\"packet\",\n",
    "                    output_mode=\"array\",\n",
    "                    output_format=\"bgr\"\n",
    "                )\n",
    "                self.hw = True\n",
    "                print(\"[INFO] Using hardware decoder (hobot_codec).\")\n",
    "            except Exception as e:\n",
    "                print(\"[WARN] hobot_codec not available or failed to init. Falling back to software decode.\")\n",
    "                print(f\"[DEBUG] hobot_codec init error: {repr(e)}\")\n",
    "\n",
    "        if not self.hw:\n",
    "            self._start_software_decoder()\n",
    "\n",
    "    def _start_software_decoder(self):\n",
    "        ffmpeg_bin = shutil.which(\"ffmpeg\")\n",
    "        if not ffmpeg_bin:\n",
    "            raise RuntimeError(\"ffmpeg required for SW fallback but not found in PATH.\")\n",
    "        if self.width is None or self.height is None:\n",
    "            raise ValueError(\"Width and height must be set for software fallback!\")\n",
    "        cmd = [\n",
    "            ffmpeg_bin,\n",
    "            \"-loglevel\", \"error\",\n",
    "            \"-hide_banner\",\n",
    "            \"-f\", \"h264\",\n",
    "            \"-i\", \"pipe:0\",\n",
    "            \"-f\", \"rawvideo\",\n",
    "            \"-pix_fmt\", \"bgr24\",\n",
    "            \"-s\", f\"{self.width}x{self.height}\",\n",
    "            \"pipe:1\"\n",
    "        ]\n",
    "        self.software_proc = subprocess.Popen(cmd, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, bufsize=0)\n",
    "        print(f\"[INFO] Started ffmpeg-based SW decoder for {self.width}x{self.height}.\")\n",
    "\n",
    "    def decode(self, nal_bytes: bytes) -> Optional[np.ndarray]:\n",
    "        if self.hw:\n",
    "            try:\n",
    "                frame = self.decoder.decode(nal_bytes)\n",
    "                return frame\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] hobot_codec decode error: {e}\")\n",
    "                return None\n",
    "\n",
    "        # SW fallback: write NAL, read a frame\n",
    "        if not self.software_proc or not self.software_proc.stdin or not self.software_proc.stdout:\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            self.software_proc.stdin.write(nal_bytes)\n",
    "            self.software_proc.stdin.flush()\n",
    "        except BrokenPipeError:\n",
    "            print(\"[ERROR] ffmpeg SW decoder pipe closed.\")\n",
    "            return None\n",
    "\n",
    "        frame_bytes_required = self.width * self.height * 3\n",
    "        frame_bytes = self.software_proc.stdout.read(frame_bytes_required)\n",
    "        if len(frame_bytes) == frame_bytes_required:\n",
    "            frame = np.frombuffer(frame_bytes, dtype=np.uint8).reshape((self.height, self.width, 3))\n",
    "            return frame\n",
    "        return None\n",
    "\n",
    "    def close(self):\n",
    "        # Clean up software proc if open\n",
    "        if self.software_proc:\n",
    "            try:\n",
    "                self.software_proc.stdin.close()\n",
    "                self.software_proc.stdout.close()\n",
    "                self.software_proc.stderr.close()\n",
    "                self.software_proc.terminate()\n",
    "            except Exception:\n",
    "                pass\n",
    "            self.software_proc = None\n",
    "\n",
    "    def __del__(self):\n",
    "        self.close()\n",
    "\n",
    "# ---------------------------\n",
    "# NAL splitting utility\n",
    "# ---------------------------\n",
    "\n",
    "def extract_nals_from_buffer(buf: bytearray):\n",
    "    start_codes = (b'\\x00\\x00\\x01', b'\\x00\\x00\\x00\\x01')\n",
    "    i = 0\n",
    "    buf_len = len(buf)\n",
    "    starts = []\n",
    "\n",
    "    while i < buf_len - 3:\n",
    "        if buf[i:i+3] == b'\\x00\\x00\\x01':\n",
    "            starts.append(i)\n",
    "            i += 3\n",
    "        elif buf[i:i+4] == b'\\x00\\x00\\x00\\x01':\n",
    "            starts.append(i)\n",
    "            i += 4\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    if not starts:\n",
    "        return []\n",
    "\n",
    "    nals = []\n",
    "    for idx, s in enumerate(starts):\n",
    "        if buf[s:s+4] == b'\\x00\\x00\\x00\\x01':\n",
    "            nal_start = s + 4\n",
    "        else:\n",
    "            nal_start = s + 3\n",
    "\n",
    "        if idx + 1 < len(starts):\n",
    "            next_s = starts[idx + 1]\n",
    "            nal = bytes(buf[nal_start:next_s])\n",
    "        else:\n",
    "            nal = bytes(buf[nal_start:])\n",
    "\n",
    "        nals.append((s, nal))\n",
    "\n",
    "    buf.clear()\n",
    "    return [nal for (_, nal) in nals]\n",
    "\n",
    "# ---------------------------\n",
    "# VideoSource abstraction\n",
    "# ---------------------------\n",
    "\n",
    "class VideoSource:\n",
    "    \"\"\"\n",
    "    Yields decoded BGR frames from file/RTSP.\n",
    "    \"\"\"\n",
    "    def __init__(self, source: str, codec: str = \"h264\", width: Optional[int] = None, height: Optional[int] = None):\n",
    "        self.source = source\n",
    "        self.codec = codec\n",
    "        self.proc = None\n",
    "        self.is_pipe = False\n",
    "        self._buffer = bytearray()\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.decoder = Decoder(codec_type=codec, width=width, height=height)\n",
    "        self._fileobj = None\n",
    "        self._start_input()\n",
    "\n",
    "    def _start_input(self):\n",
    "        lower = self.source.lower()\n",
    "        if lower.endswith(\".h264\") or lower.endswith(\".h265\"):\n",
    "            self.is_pipe = False\n",
    "            self.proc = None\n",
    "            self._fileobj = open(self.source, \"rb\")\n",
    "            print(f\"[INFO] Opening raw file {self.source}\")\n",
    "            return\n",
    "\n",
    "        ffmpeg_bin = shutil.which(\"ffmpeg\")\n",
    "        if not ffmpeg_bin:\n",
    "            raise RuntimeError(\"ffmpeg not found in PATH.\")\n",
    "\n",
    "        cmd = [\n",
    "            ffmpeg_bin,\n",
    "            \"-loglevel\", \"error\",\n",
    "            \"-i\", self.source,\n",
    "            \"-c:v\", \"copy\",\n",
    "            \"-f\", \"h264\",\n",
    "            \"pipe:1\"\n",
    "        ]\n",
    "\n",
    "        self.proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, bufsize=0)\n",
    "        self.is_pipe = True\n",
    "        print(f\"[INFO] Started ffmpeg - streaming raw {self.codec} from {self.source}\")\n",
    "\n",
    "    def frames(self) -> Generator[Tuple[np.ndarray, float], None, None]:\n",
    "        if not self.is_pipe:\n",
    "            data = self._fileobj.read()\n",
    "            if not data:\n",
    "                return\n",
    "            self._buffer.extend(data)\n",
    "            nals = extract_nals_from_buffer(self._buffer)\n",
    "            for nal in nals:\n",
    "                t0 = time.time()\n",
    "                frame = self.decoder.decode(nal)\n",
    "                if frame is not None:\n",
    "                    yield frame, (time.time() - t0) * 1000.0\n",
    "            return\n",
    "\n",
    "        assert self.proc is not None and self.proc.stdout is not None\n",
    "        stdout = self.proc.stdout\n",
    "\n",
    "        try:\n",
    "            while True:\n",
    "                chunk = stdout.read(4096)\n",
    "                if not chunk:\n",
    "                    nals = extract_nals_from_buffer(self._buffer)\n",
    "                    for nal in nals:\n",
    "                        t0 = time.time()\n",
    "                        frame = self.decoder.decode(nal)\n",
    "                        if frame is not None:\n",
    "                            yield frame, (time.time() - t0) * 1000.0\n",
    "                    break\n",
    "\n",
    "                self._buffer.extend(chunk)\n",
    "                nals = extract_nals_from_buffer(self._buffer)\n",
    "                for nal in nals:\n",
    "                    t0 = time.time()\n",
    "                    frame = self.decoder.decode(nal)\n",
    "                    if frame is not None:\n",
    "                        yield frame, (time.time() - t0) * 1000.0\n",
    "\n",
    "        finally:\n",
    "            if self.proc:\n",
    "                try:\n",
    "                    self.proc.kill()\n",
    "                except Exception:\n",
    "                    pass\n",
    "            if self._fileobj:\n",
    "                self._fileobj.close()\n",
    "            self.decoder.close()\n",
    "\n",
    "# ---------------------------\n",
    "# Example main for test/debug\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    import cv2\n",
    "\n",
    "    source = DEFAULT_SOURCE\n",
    "    width = DEFAULT_WIDTH\n",
    "    height = DEFAULT_HEIGHT\n",
    "\n",
    "    src = VideoSource(source, \"h264\", width, height)\n",
    "    for idx, (frame, latency_ms) in enumerate(src.frames()):\n",
    "        print(f\"Frame {idx}: latency={latency_ms:.2f} ms shape={frame.shape}\")\n",
    "        if OUTPUT_WINDOW:\n",
    "            cv2.imshow(\"Decoded\", frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    cv2.destroyAllWindows()\n",
    "    src.decoder.close()"
   ],
   "id": "1ba7a5995aad734a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] hobot_codec not available or failed to init. Falling back to software decode.\n",
      "[DEBUG] hobot_codec init error: ModuleNotFoundError(\"No module named 'hobot_codec'\")\n",
      "[INFO] Started ffmpeg-based SW decoder for 640x360.\n",
      "[INFO] Started ffmpeg - streaming raw h264 from test.mp4\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#!/usr/bin/env python3\n",
    "import gi\n",
    "gi.require_version('Gst', '1.0')\n",
    "gi.require_version('GstRtspServer', '1.0')\n",
    "gi.require_version('GLib', '2.0')\n",
    "\n",
    "from gi.repository import Gst, GstRtspServer, GLib\n",
    "\n",
    "Gst.init(None)\n",
    "VIDEO_PATH = \"/home/sunrise/BreadCounting/output2.mp4\"\n",
    "\n",
    "class CameraFactory(GstRtspServer.RTSPMediaFactory):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.set_shared(True)\n",
    "        self.set_latency(200)\n",
    "        self.set_clock(Gst.SystemClock.obtain())\n",
    "        self.set_stop_on_disconnect(True)\n",
    "\n",
    "    def do_create_element(self, url):\n",
    "        pipeline = (\n",
    "            f\"filesrc location={VIDEO_PATH} ! qtdemux name=demux \"\n",
    "            f\"demux.video_0 ! queue ! decodebin ! videoconvert ! videoscale ! \"\n",
    "            f\"video/x-raw,width=1280,height=720 ! \"\n",
    "            f\"openh264enc bitrate=2048 ! h264parse ! rtph264pay name=pay0 pt=96 config-interval=1\"\n",
    "        )\n",
    "\n",
    "        return Gst.parse_launch(pipeline)\n",
    "\n",
    "def main():\n",
    "    server = GstRtspServer.RTSPServer()\n",
    "    factory = CameraFactory()\n",
    "    server.get_mount_points().add_factory(\"/test_cam\", factory)\n",
    "    server.attach(None)\n",
    "    print(\"720p RTSP Camera running at rtsp://127.0.0.1:8554/test_cam\")\n",
    "    loop = GLib.MainLoop()\n",
    "    loop.run()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "id": "fa9f7b8ccd6dcfad"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
