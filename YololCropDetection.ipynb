{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-11-21T05:52:29.882953Z"
    }
   },
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "import uuid\n",
    "\n",
    "# --- CONFIG ---\n",
    "MODEL_PATH = \"best_detect.pt\"  # your YOLO model\n",
    "# DIRS = [\"red_frames\", \"blue_frames\", \"brown_frames\", \"dark_brown_frames\", \"yellow_frames\", \"green_frames\"]\n",
    "DIRS = [\"red_frames\"]\n",
    "IMAGES_ROOT_DIR = \"D:\\\\Recordings\\\\2025_11_07\"\n",
    "# IMAGES_DIR = \"D:\\\\Recordings\\\\2025_11_07\\\\red_frames\"    # folder containing original images\n",
    "OUTPUT_DIR = \"D:\\\\Recordings\\\\2025_11_07\\\\CNN_cropped_frames\\\\red\"    # folder where crops will be saved\n",
    "CONFIDENCE_THRESHOLD = 0.8\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Load YOLO model\n",
    "model = YOLO(MODEL_PATH)\n",
    "\n",
    "for image_dir in DIRS:\n",
    "# Iterate through all images\n",
    "    IMAGES_DIR = os.path.join(IMAGES_ROOT_DIR, image_dir)\n",
    "    for filename in os.listdir(IMAGES_DIR):\n",
    "        if not filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            continue\n",
    "\n",
    "        img_path = os.path.join(IMAGES_DIR, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        results = model(img)[0]\n",
    "\n",
    "        for i, box in enumerate(results.boxes):\n",
    "            cls_id = int(box.cls[0])\n",
    "            conf = float(box.conf[0])\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "\n",
    "            # Skip low-confidence detections\n",
    "            if conf < CONFIDENCE_THRESHOLD:\n",
    "                continue\n",
    "\n",
    "            crop = img[y1:y2, x1:x2]\n",
    "\n",
    "            # Create a unique name\n",
    "            crop_name = f\"{filename.split('.')[0]}_{cls_id}_{conf:.2f}_{uuid.uuid4().hex[:8]}.jpg\"\n",
    "            crop_path = os.path.join(OUTPUT_DIR, crop_name)\n",
    "\n",
    "            cv2.imwrite(crop_path, crop)\n",
    "\n",
    "print(\"Cropping complete.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 bread-bag-closed, 92.1ms\n",
      "Speed: 5.1ms preprocess, 92.1ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bread-bag-closed, 88.8ms\n",
      "Speed: 5.4ms preprocess, 88.8ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bread-bag-closed, 88.9ms\n",
      "Speed: 6.0ms preprocess, 88.9ms inference, 7.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 88.9ms\n",
      "Speed: 5.3ms preprocess, 88.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 55.7ms\n",
      "Speed: 5.4ms preprocess, 55.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 44.7ms\n",
      "Speed: 4.9ms preprocess, 44.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.6ms\n",
      "Speed: 6.6ms preprocess, 45.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bread-bag-closed, 1 bread-bag-opened, 44.5ms\n",
      "Speed: 4.7ms preprocess, 44.5ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bread-bag-closed, 44.5ms\n",
      "Speed: 4.6ms preprocess, 44.5ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bread-bag-closed, 44.7ms\n",
      "Speed: 4.7ms preprocess, 44.7ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bread-bag-closed, 44.7ms\n",
      "Speed: 4.6ms preprocess, 44.7ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bread-bag-closed, 44.7ms\n",
      "Speed: 4.8ms preprocess, 44.7ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 bread-bag-closeds, 44.6ms\n",
      "Speed: 4.5ms preprocess, 44.6ms inference, 8.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 bread-bag-closeds, 44.7ms\n",
      "Speed: 4.8ms preprocess, 44.7ms inference, 10.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 bread-bag-closeds, 44.8ms\n",
      "Speed: 4.7ms preprocess, 44.8ms inference, 8.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 bread-bag-closeds, 45.0ms\n",
      "Speed: 4.4ms preprocess, 45.0ms inference, 9.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bread-bag-closed, 1 bread-bag-opened, 44.5ms\n",
      "Speed: 4.4ms preprocess, 44.5ms inference, 9.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bread-bag-closed, 1 bread-bag-opened, 44.5ms\n",
      "Speed: 4.5ms preprocess, 44.5ms inference, 10.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bread-bag-closed, 44.6ms\n",
      "Speed: 4.6ms preprocess, 44.6ms inference, 7.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 bread-bag-closeds, 1 bread-bag-opened, 44.6ms\n",
      "Speed: 5.0ms preprocess, 44.6ms inference, 8.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 bread-bag-closeds, 44.6ms\n",
      "Speed: 4.6ms preprocess, 44.6ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 bread-bag-closeds, 45.3ms\n",
      "Speed: 5.2ms preprocess, 45.3ms inference, 13.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 bread-bag-closeds, 1 bread-bag-opened, 44.5ms\n",
      "Speed: 4.7ms preprocess, 44.5ms inference, 14.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 bread-bag-closeds, 1 bread-bag-opened, 44.8ms\n",
      "Speed: 4.7ms preprocess, 44.8ms inference, 14.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 bread-bag-closeds, 44.6ms\n",
      "Speed: 5.1ms preprocess, 44.6ms inference, 13.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 bread-bag-closeds, 1 bread-bag-opened, 45.3ms\n",
      "Speed: 4.8ms preprocess, 45.3ms inference, 15.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 bread-bag-closeds, 44.8ms\n",
      "Speed: 5.0ms preprocess, 44.8ms inference, 16.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 bread-bag-closeds, 1 bread-bag-opened, 45.4ms\n",
      "Speed: 4.6ms preprocess, 45.4ms inference, 15.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 bread-bag-closeds, 44.9ms\n",
      "Speed: 5.3ms preprocess, 44.9ms inference, 22.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 bread-bag-closeds, 44.6ms\n",
      "Speed: 4.6ms preprocess, 44.6ms inference, 19.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 bread-bag-closeds, 44.6ms\n",
      "Speed: 4.6ms preprocess, 44.6ms inference, 20.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 bread-bag-closeds, 1 bread-bag-opened, 44.5ms\n",
      "Speed: 4.7ms preprocess, 44.5ms inference, 30.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 bread-bag-closeds, 45.5ms\n",
      "Speed: 5.0ms preprocess, 45.5ms inference, 22.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 bread-bag-closeds, 1 bread-bag-opened, 45.3ms\n",
      "Speed: 5.9ms preprocess, 45.3ms inference, 20.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 bread-bag-closeds, 44.6ms\n",
      "Speed: 4.7ms preprocess, 44.6ms inference, 23.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 bread-bag-closeds, 45.4ms\n",
      "Speed: 5.6ms preprocess, 45.4ms inference, 14.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 bread-bag-closeds, 44.7ms\n",
      "Speed: 4.5ms preprocess, 44.7ms inference, 18.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 bread-bag-closeds, 45.2ms\n",
      "Speed: 5.2ms preprocess, 45.2ms inference, 21.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
